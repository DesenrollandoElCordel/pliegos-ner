{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59bbea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0316f093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les remplacements ont été effectués et le fichier sauvegardé.\n"
     ]
    }
   ],
   "source": [
    "file_path = 'NER_List_All_18.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Dictionnaire des remplacements\n",
    "replacements = {\n",
    "    'Historias': 'Textos Narrativos',\n",
    "    'Relaciones': 'Textos Narrativos',\n",
    "    'Relaciones de sucesos': 'Textos Narrativos',\n",
    "    'Romances': 'Textos Narrativos',\n",
    "    'Chascos': 'Textos Narrativos',\n",
    "    'Canciones': 'Poesías y Canciones',\n",
    "    'Coplas': 'Poesías y Canciones',\n",
    "    'Décimas': 'Poesías y Canciones',\n",
    "    'Glosas': 'Poesías y Canciones',\n",
    "    'Seguidillas': 'Poesías y Canciones',\n",
    "    'Trovos': 'Poesías y Canciones',\n",
    "    'Villancicos': 'Poesías y Canciones',\n",
    "    'Jácaras': 'Poesías y Canciones',\n",
    "    'Chistes': 'Poesías y Canciones',\n",
    "    'Sainetes': 'Textos Dramáticos y Teatrales',\n",
    "    'Diálogos': 'Textos Dramáticos y Teatrales',\n",
    "    'Coloquios': 'Textos Dramáticos y Teatrales',\n",
    "    'Pasillos': 'Textos Dramáticos y Teatrales',\n",
    "    'Entremeses': 'Textos Dramáticos y Teatrales',\n",
    "    'Matracas': 'Textos Dramáticos y Teatrales',\n",
    "    'Cartas': 'Textos Diversos',\n",
    "    'Evangelios': 'Textos Diversos',\n",
    "    'Recetas': 'Textos Diversos',\n",
    "    'Oraciones': 'Textos Diversos',\n",
    "    'Testamentos': 'Textos Diversos',\n",
    "    'Sátiras': 'Textos Diversos'\n",
    "}\n",
    "\n",
    "# Remplacer les valeurs\n",
    "df['type_text'] = df['type_text'].replace(replacements)\n",
    "\n",
    "# Sauvegarder le fichier modifié\n",
    "output_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/moreno-ner/Ner_All_Typtext.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Les remplacements ont été effectués et le fichier sauvegardé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc09727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6043b1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noms de colonnes disponibles :\n",
      "Index(['index', 'id_doc', 'original_name', 'id_wkd', 'type_place',\n",
      "       'normalized_name', 'latitude', 'longitude', 'shortTitle', 'pubPlace',\n",
      "       'printer', 'date', 'type_text', 'genre', 'url'],\n",
      "      dtype='object')\n",
      "Lignes avec des valeurs manquantes ou vides dans `type_text` :\n",
      "Empty DataFrame\n",
      "Columns: [index, id_doc, original_name, id_wkd, type_place, normalized_name, latitude, longitude, shortTitle, pubPlace, printer, date, type_text, genre, url]\n",
      "Index: []\n",
      "Le fichier résultat a été créé avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Ner_All_Typtext.csv'\n",
    "df = pd.read_csv(file_path, sep=';', skipinitialspace=True)\n",
    "\n",
    "# Vérifier les noms de colonnes\n",
    "print(\"Noms de colonnes disponibles :\")\n",
    "print(df.columns)\n",
    "\n",
    "# Afficher les lignes avec des valeurs manquantes ou vides dans `type_text`\n",
    "missing_type_text = df[df['type_text'].isna() | (df['type_text'] == '')]\n",
    "print(\"Lignes avec des valeurs manquantes ou vides dans `type_text` :\")\n",
    "print(missing_type_text)\n",
    "\n",
    "# Sauvegarder ces lignes dans un fichier CSV pour une analyse plus détaillée\n",
    "missing_type_text.to_csv('/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/missing_type_text.csv', sep=';', index=False)\n",
    "\n",
    "# Grouper les données par 'normalized_name' et calculer le type de texte le plus fréquent et son nombre d'occurrences\n",
    "if 'normalized_name' in df.columns:\n",
    "    grouped = df.groupby('normalized_name')\n",
    "    \n",
    "    def most_frequent_value(series):\n",
    "        if series.empty:\n",
    "            return None\n",
    "        return series.value_counts().idxmax()\n",
    "\n",
    "    def max_count(series):\n",
    "        if series.empty:\n",
    "            return 0\n",
    "        return series.value_counts().max()\n",
    "\n",
    "    most_frequent_text_type = grouped['type_text'].agg(most_frequent_value)\n",
    "    most_frequent_count = grouped['type_text'].agg(max_count)\n",
    "\n",
    "    # Trouver les identifiants des documents pour les occurrences majoritaires et les formater\n",
    "    def get_major_ids(group):\n",
    "        if group['type_text'].empty:\n",
    "            return ''\n",
    "        most_frequent = group['type_text'].value_counts().idxmax()\n",
    "        ids = group[group['type_text'] == most_frequent]['id_doc']\n",
    "        id_counts = ids.value_counts()\n",
    "        return ', '.join(f\"{id} ({count})\" if count > 1 else f\"{id}\" for id, count in id_counts.items())\n",
    "\n",
    "    most_frequent_ids = grouped.apply(get_major_ids)\n",
    "\n",
    "    # Filtrer les résultats pour supprimer les valeurs None ou vides\n",
    "    results = pd.DataFrame({\n",
    "        'normalized_name': most_frequent_text_type.index,\n",
    "        'type_text': most_frequent_text_type.values,\n",
    "        'occurrence': most_frequent_count.values,\n",
    "        'id_doc': most_frequent_ids.values\n",
    "    }).dropna()\n",
    "\n",
    "    # Extraire les coordonnées (longitude et latitude) sans les grouper\n",
    "    # Prendre la première instance des coordonnées par 'normalized_name'\n",
    "    first_instance = df.drop_duplicates(subset=['normalized_name'])\n",
    "    coordinates = first_instance[['normalized_name', 'longitude', 'latitude']].set_index('normalized_name')\n",
    "\n",
    "    # Joindre les coordonnées avec le DataFrame des résultats\n",
    "    results = results.join(coordinates, on='normalized_name')\n",
    "\n",
    "    # Sauvegarder le nouveau fichier CSV\n",
    "    output_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Carto/ner_All_typetext_city.csv'\n",
    "    results.to_csv(output_path, sep=';', index=False)\n",
    "\n",
    "    print(\"Le fichier résultat a été créé avec succès.\")\n",
    "else:\n",
    "    print(\"La colonne 'normalized_name' n'existe pas dans le fichier CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaa64bb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'coord'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'coord'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Assumons que les coordonnées sont sous forme de 'latitude,longitude'\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoord\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/frame.py:3760\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3760\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3762\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'coord'"
     ]
    }
   ],
   "source": [
    "# Charger le fichier CSV\n",
    "file_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Carto/ner_Moreno_typetext_city_gutgut.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Fonction pour créer un GeoJSON point\n",
    "def create_geojson_point(row):\n",
    "    geojson_feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [row['latitude'], row['longitude']]\n",
    "        },\n",
    "        \"properties\": {\n",
    "            # Ajoutez ici toutes les propriétés supplémentaires que vous souhaitez inclure\n",
    "            \"name\": row.get('name', 'No Name')  # Assurez-vous que cette colonne existe ou modifiez en conséquence\n",
    "        }\n",
    "    }\n",
    "    return geojson_feature\n",
    "\n",
    "# Appliquer la fonction à chaque ligne du DataFrame\n",
    "df['geojson'] = df.apply(create_geojson_point, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfad2ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données :\n",
      "  ï»¿normalized_name;type_text;occurrence;id_doc;longitude;latitude\n",
      "0  Acebedo;Textos Narrativos;1;Moreno_320;43.0391...               \n",
      "1  Adra;Textos Narrativos;3;\"Moreno_180 (2); More...               \n",
      "2  Alaejos;Textos Narrativos;2;\"Moreno_083; Moren...               \n",
      "3  Alajerââ¥;Poesââ as y Canciones;1;Moreno...               \n",
      "4  Alameda;Textos Narrativos;1;Moreno_104;37.2084...               \n",
      "Le fichier a été ré-encodé et sauvegardé sous /Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Carto/ner_Moreno_typetext_city_UTF8.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Spécifiez le chemin de votre fichier CSV\n",
    "file_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Carto/ner_Moreno_typetext_city_gutgut.csv'\n",
    "\n",
    "# Lire le fichier avec l'encodage incorrect supposé (par exemple 'latin1')\n",
    "df = pd.read_csv(file_path, sep=',', encoding='latin1', skipinitialspace=True)\n",
    "\n",
    "# Vérifier les premières lignes pour s'assurer que les données sont correctement lues\n",
    "print(\"Aperçu des données :\")\n",
    "print(df.head())\n",
    "\n",
    "# Sauvegarder le fichier avec l'encodage correct (utf-8)\n",
    "new_file_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Carto/ner_Moreno_typetext_city_UTF8.csv'\n",
    "df.to_csv(new_file_path, sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "print(f\"Le fichier a été ré-encodé et sauvegardé sous {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109bd5c8",
   "metadata": {},
   "source": [
    "**Gravure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d237bf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données :\n",
      "      Code gravure Code pliegos       Page       Coordonnees   Titre pliegos   \n",
      "0  grabado_b_001_1      BCN_001  BCN_001_1   450,149,950,800  Curiosa xacara  \\\n",
      "1  grabado_b_002_1      BCN_002  BCN_002_1   465,154,400,670    Xacara nueva   \n",
      "2  grabado_b_002_2      BCN_002  BCN_002_1   950,160,350,650    Xacara nueva   \n",
      "3  grabado_b_003_1      BCN_003  BCN_003_1  345,256,1200,830   Nuevo romance   \n",
      "4  grabado_b_004_1      BCN_004  BCN_004_1   921,158,470,735    Blas de Leon   \n",
      "\n",
      "     Date                 Impresor personaje_masculino personaje_femenino   \n",
      "0  [s.a.]  Herederos de Juan Jolis                 NaN                NaN  \\\n",
      "1  [s.a.]  Herederos de Juan Jolis              hombre                NaN   \n",
      "2  [s.a.]  Herederos de Juan Jolis                 NaN              mujer   \n",
      "3  [s.a.]  Herederos de Juan Jolis                 NaN                NaN   \n",
      "4  [s.a.]  Herederos de Juan Jolis              hombre                NaN   \n",
      "\n",
      "  ninos  ...   accion  muerte religion animales accesorios construidos   \n",
      "0   NaN  ...  rezando  muerte      NaN      NaN      armas    interior  \\\n",
      "1   NaN  ...      NaN     NaN      NaN      NaN        NaN         NaN   \n",
      "2   NaN  ...      NaN     NaN      NaN      NaN        NaN         NaN   \n",
      "3   NaN  ...      NaN  muerte      NaN      NaN      armas      ciudad   \n",
      "4   NaN  ...      NaN     NaN      NaN      NaN      armas         NaN   \n",
      "\n",
      "  naturales transporte escudo Unnamed: 20  \n",
      "0       NaN        NaN    NaN         NaN  \n",
      "1       NaN        NaN    NaN         NaN  \n",
      "2       NaN        NaN    NaN         NaN  \n",
      "3   paisaje        NaN    NaN         NaN  \n",
      "4       NaN        NaN    NaN         NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Le fichier résultat a été créé avec succès : /Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Index_Grabados_Moreno+Varios_comptes.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lire le fichier Excel\n",
    "file_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Carto/Woodcuts_all.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Afficher un aperçu des données pour vérifier les colonnes disponibles\n",
    "print(\"Aperçu des données :\")\n",
    "print(df.head())\n",
    "\n",
    "# Liste des catégories à analyser\n",
    "categories = [\n",
    "    'personaje_masculino', 'personaje_femenino', 'grupos_personajes', 'muerte', 'religion', 'animales', 'construidos',\n",
    "    'naturales', 'transporte'\n",
    "]\n",
    "\n",
    "# Fonction pour compter les occurrences non-nulles par catégorie pour chaque code pliegos\n",
    "def count_categories(group):\n",
    "    result = {}\n",
    "    for category in categories:\n",
    "        count = group[category].notna().sum()\n",
    "        result[category] = count\n",
    "    return pd.Series(result)\n",
    "\n",
    "# Grouper par 'Code pliegos' et appliquer la fonction de comptage\n",
    "grouped = df.groupby('Code pliegos').apply(count_categories).reset_index()\n",
    "\n",
    "# Joindre les résultats avec le DataFrame original\n",
    "df = df.drop(columns=categories).drop_duplicates(subset=['Code pliegos'])\n",
    "df = df.merge(grouped, on='Code pliegos', suffixes=('', '_count'))\n",
    "\n",
    "# Sauvegarder le nouveau fichier Excel avec les résultats\n",
    "output_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Index_Grabados_Moreno+Varios_comptes.xlsx'\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Le fichier résultat a été créé avec succès : {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dbb9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lire le fichier Excel avec les comptages\n",
    "count_file_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Index_Grabados_Moreno+Varios_comptes.xlsx'\n",
    "count_df = pd.read_excel(count_file_path)\n",
    "\n",
    "# Lire le fichier CSV avec les `id_doc` en essayant de vérifier l'encodage\n",
    "id_doc_file_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Carto/NER_List_All_18.csv'\n",
    "try:\n",
    "    id_doc_df = pd.read_csv(id_doc_file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    id_doc_df = pd.read_csv(id_doc_file_path, encoding='latin1')\n",
    "\n",
    "# Sélectionner uniquement les colonnes nécessaires pour la jointure\n",
    "columns_to_merge = [\n",
    "    'Code pliegos', 'personaje_masculino', 'personaje_femenino',\n",
    "    'grupos_personajes', 'muerte', 'religion', 'animales', 'construidos', 'naturales', 'transporte'\n",
    "]\n",
    "count_df = count_df[columns_to_merge]\n",
    "\n",
    "# Joindre les deux DataFrames sur `id_doc`\n",
    "merged_df = id_doc_df.merge(count_df, left_on='id_doc', right_on='Code pliegos', how='left')\n",
    "\n",
    "# Supprimer la colonne 'Code pliegos' après la jointure si nécessaire\n",
    "merged_df = merged_df.drop(columns=['Code pliegos'])\n",
    "\n",
    "# Sauvegarder le nouveau fichier CSV avec les résultats en essayant avec latin1\n",
    "output_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/moreno-ner/NER_Grabados_Moreno+varios.csv'\n",
    "merged_df.to_csv(output_path, index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaee8833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier résultat a été créé avec succès : /Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Carto/GrabadosMoreno+Varios_with_percentages.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lire le fichier CSV avec les informations de comptage et les coordonnées\n",
    "file_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/moreno-ner/NER_Grabados_Moreno+varios.csv'\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Liste des catégories à analyser\n",
    "categories = [\n",
    "    'personaje_masculino', 'personaje_femenino', 'grupos_personajes', 'muerte', 'religion', 'animales', 'construidos',\n",
    "    'naturales', 'transporte'\n",
    "]\n",
    "\n",
    "# Fonction pour calculer le pourcentage de la catégorie la plus représentée\n",
    "def calculate_percentage(group):\n",
    "    total_counts = group[categories].sum()\n",
    "    max_category = total_counts.idxmax()\n",
    "    max_count = total_counts.max()\n",
    "    total = total_counts.sum()\n",
    "    percentage = (max_count / total) * 100 if total > 0 else 0\n",
    "    return pd.Series([max_category, percentage], index=['Grabados', 'porcentaje'])\n",
    "\n",
    "# Fonction pour rassembler les id_doc avec leurs occurrences\n",
    "def gather_ids(group):\n",
    "    id_counts = group['id_doc'].value_counts()\n",
    "    return ', '.join(f\"{id} ({count})\" if count > 1 else f\"{id}\" for id, count in id_counts.items())\n",
    "\n",
    "# Grouper par 'normalized_name' et appliquer les fonctions\n",
    "grouped = df.groupby('normalized_name').apply(calculate_percentage).reset_index()\n",
    "grouped_ids = df.groupby('normalized_name').apply(lambda x: pd.Series({\n",
    "    'id_doc': gather_ids(x),\n",
    "    'longitude': x['longitude'].iloc[0],\n",
    "    'latitude': x['latitude'].iloc[0]\n",
    "})).reset_index()\n",
    "\n",
    "# Joindre les résultats avec les coordonnées\n",
    "results = grouped_ids.merge(grouped, on='normalized_name')\n",
    "\n",
    "# Sauvegarder le nouveau fichier CSV avec les résultats\n",
    "output_path = '/Users/pauline/Documents/DocumentsSandoz/Sandoz/pliegos-ner/Carto/GrabadosMoreno+Varios_with_percentages.csv'\n",
    "results.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Le fichier résultat a été créé avec succès : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2aebec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
