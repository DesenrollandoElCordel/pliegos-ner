2023-05-11 10:42:45,137 ----------------------------------------------------------------------------------------------------
2023-05-11 10:42:45,137 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(31003, 768)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-11): 12 x BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=768, out_features=5, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-05-11 10:42:45,137 ----------------------------------------------------------------------------------------------------
2023-05-11 10:42:45,137 Corpus: "Corpus: 2958 train + 433 dev + 641 test sentences"
2023-05-11 10:42:45,137 ----------------------------------------------------------------------------------------------------
2023-05-11 10:42:45,137 Parameters:
2023-05-11 10:42:45,137  - learning_rate: "0.000005"
2023-05-11 10:42:45,137  - mini_batch_size: "4"
2023-05-11 10:42:45,137  - patience: "3"
2023-05-11 10:42:45,137  - anneal_factor: "0.5"
2023-05-11 10:42:45,137  - max_epochs: "10"
2023-05-11 10:42:45,137  - shuffle: "True"
2023-05-11 10:42:45,137  - train_with_dev: "False"
2023-05-11 10:42:45,137  - batch_growth_annealing: "False"
2023-05-11 10:42:45,137 ----------------------------------------------------------------------------------------------------
2023-05-11 10:42:45,137 Model training base path: "ner-bertSpanish-fineTuning"
2023-05-11 10:42:45,153 ----------------------------------------------------------------------------------------------------
2023-05-11 10:42:45,153 Device: cuda:0
2023-05-11 10:42:45,153 ----------------------------------------------------------------------------------------------------
2023-05-11 10:42:45,153 Embeddings storage mode: none
2023-05-11 10:42:45,153 ----------------------------------------------------------------------------------------------------
2023-05-11 10:42:56,819 epoch 1 - iter 74/740 - loss 1.46774386 - time (sec): 11.67 - samples/sec: 634.49 - lr: 0.000001
2023-05-11 10:43:08,199 epoch 1 - iter 148/740 - loss 1.27919537 - time (sec): 23.05 - samples/sec: 672.54 - lr: 0.000001
2023-05-11 10:43:19,767 epoch 1 - iter 222/740 - loss 0.99239611 - time (sec): 34.61 - samples/sec: 663.04 - lr: 0.000002
2023-05-11 10:43:31,690 epoch 1 - iter 296/740 - loss 0.70607574 - time (sec): 46.54 - samples/sec: 716.45 - lr: 0.000002
2023-05-11 10:43:43,685 epoch 1 - iter 370/740 - loss 0.53876509 - time (sec): 58.53 - samples/sec: 754.99 - lr: 0.000003
2023-05-11 10:43:55,098 epoch 1 - iter 444/740 - loss 0.48060103 - time (sec): 69.95 - samples/sec: 710.33 - lr: 0.000003
2023-05-11 10:44:06,502 epoch 1 - iter 518/740 - loss 0.45045392 - time (sec): 81.35 - samples/sec: 651.93 - lr: 0.000003
2023-05-11 10:44:18,388 epoch 1 - iter 592/740 - loss 0.38957665 - time (sec): 93.24 - samples/sec: 661.22 - lr: 0.000004
2023-05-11 10:44:29,907 epoch 1 - iter 666/740 - loss 0.35088170 - time (sec): 104.75 - samples/sec: 654.70 - lr: 0.000005
2023-05-11 10:44:41,495 epoch 1 - iter 740/740 - loss 0.32193709 - time (sec): 116.34 - samples/sec: 651.72 - lr: 0.000005
2023-05-11 10:44:41,495 ----------------------------------------------------------------------------------------------------
2023-05-11 10:44:41,495 EPOCH 1 done: loss 0.3219 - lr 0.000005
2023-05-11 10:44:46,537 Evaluating as a multi-label problem: False
2023-05-11 10:44:46,547 DEV : loss 0.008526043966412544 - f1-score (micro avg)  0.7826
2023-05-11 10:44:46,557 ----------------------------------------------------------------------------------------------------
2023-05-11 10:44:58,171 epoch 2 - iter 74/740 - loss 0.01214055 - time (sec): 11.61 - samples/sec: 616.30 - lr: 0.000005
2023-05-11 10:45:09,994 epoch 2 - iter 148/740 - loss 0.01191433 - time (sec): 23.44 - samples/sec: 608.27 - lr: 0.000005
2023-05-11 10:45:21,754 epoch 2 - iter 222/740 - loss 0.01404188 - time (sec): 35.20 - samples/sec: 629.48 - lr: 0.000005
2023-05-11 10:45:33,283 epoch 2 - iter 296/740 - loss 0.01207634 - time (sec): 46.73 - samples/sec: 626.35 - lr: 0.000005
2023-05-11 10:45:45,060 epoch 2 - iter 370/740 - loss 0.01193403 - time (sec): 58.50 - samples/sec: 621.40 - lr: 0.000005
2023-05-11 10:45:56,828 epoch 2 - iter 444/740 - loss 0.01239237 - time (sec): 70.27 - samples/sec: 627.60 - lr: 0.000005
2023-05-11 10:46:08,701 epoch 2 - iter 518/740 - loss 0.01046040 - time (sec): 82.14 - samples/sec: 640.14 - lr: 0.000005
2023-05-11 10:46:20,523 epoch 2 - iter 592/740 - loss 0.01120490 - time (sec): 93.97 - samples/sec: 645.60 - lr: 0.000005
2023-05-11 10:46:32,273 epoch 2 - iter 666/740 - loss 0.01085658 - time (sec): 105.72 - samples/sec: 645.03 - lr: 0.000005
2023-05-11 10:46:44,050 epoch 2 - iter 740/740 - loss 0.01127013 - time (sec): 117.49 - samples/sec: 645.34 - lr: 0.000004
2023-05-11 10:46:44,050 ----------------------------------------------------------------------------------------------------
2023-05-11 10:46:44,050 EPOCH 2 done: loss 0.0113 - lr 0.000004
2023-05-11 10:46:49,251 Evaluating as a multi-label problem: False
2023-05-11 10:46:49,256 DEV : loss 0.006995759904384613 - f1-score (micro avg)  0.8696
2023-05-11 10:46:49,266 ----------------------------------------------------------------------------------------------------
2023-05-11 10:47:00,979 epoch 3 - iter 74/740 - loss 0.00874285 - time (sec): 11.71 - samples/sec: 645.20 - lr: 0.000004
2023-05-11 10:47:12,577 epoch 3 - iter 148/740 - loss 0.00931307 - time (sec): 23.31 - samples/sec: 651.93 - lr: 0.000004
2023-05-11 10:47:24,143 epoch 3 - iter 222/740 - loss 0.01013101 - time (sec): 34.88 - samples/sec: 665.70 - lr: 0.000004
2023-05-11 10:47:35,856 epoch 3 - iter 296/740 - loss 0.00829477 - time (sec): 46.59 - samples/sec: 673.09 - lr: 0.000004
2023-05-11 10:47:47,491 epoch 3 - iter 370/740 - loss 0.00757960 - time (sec): 58.23 - samples/sec: 670.58 - lr: 0.000004
2023-05-11 10:47:59,058 epoch 3 - iter 444/740 - loss 0.00689442 - time (sec): 69.79 - samples/sec: 661.33 - lr: 0.000004
2023-05-11 10:48:10,636 epoch 3 - iter 518/740 - loss 0.00822413 - time (sec): 81.37 - samples/sec: 654.53 - lr: 0.000004
2023-05-11 10:48:22,343 epoch 3 - iter 592/740 - loss 0.00732291 - time (sec): 93.08 - samples/sec: 654.91 - lr: 0.000004
2023-05-11 10:48:33,938 epoch 3 - iter 666/740 - loss 0.00718908 - time (sec): 104.67 - samples/sec: 651.05 - lr: 0.000004
2023-05-11 10:48:45,322 epoch 3 - iter 740/740 - loss 0.00829271 - time (sec): 116.06 - samples/sec: 653.33 - lr: 0.000004
2023-05-11 10:48:45,322 ----------------------------------------------------------------------------------------------------
2023-05-11 10:48:45,322 EPOCH 3 done: loss 0.0083 - lr 0.000004
2023-05-11 10:48:50,628 Evaluating as a multi-label problem: False
2023-05-11 10:48:50,638 DEV : loss 0.006591013167053461 - f1-score (micro avg)  0.875
2023-05-11 10:48:50,657 ----------------------------------------------------------------------------------------------------
2023-05-11 10:49:02,337 epoch 4 - iter 74/740 - loss 0.00329344 - time (sec): 11.68 - samples/sec: 752.94 - lr: 0.000004
2023-05-11 10:49:14,112 epoch 4 - iter 148/740 - loss 0.00437597 - time (sec): 23.45 - samples/sec: 712.25 - lr: 0.000004
2023-05-11 10:49:26,101 epoch 4 - iter 222/740 - loss 0.00492993 - time (sec): 35.44 - samples/sec: 698.96 - lr: 0.000004
2023-05-11 10:49:37,674 epoch 4 - iter 296/740 - loss 0.00389198 - time (sec): 47.02 - samples/sec: 679.64 - lr: 0.000004
2023-05-11 10:49:49,185 epoch 4 - iter 370/740 - loss 0.00327084 - time (sec): 58.53 - samples/sec: 669.14 - lr: 0.000004
2023-05-11 10:50:00,731 epoch 4 - iter 444/740 - loss 0.00423939 - time (sec): 70.07 - samples/sec: 665.88 - lr: 0.000004
2023-05-11 10:50:12,352 epoch 4 - iter 518/740 - loss 0.00416704 - time (sec): 81.69 - samples/sec: 660.21 - lr: 0.000004
2023-05-11 10:50:24,351 epoch 4 - iter 592/740 - loss 0.00452723 - time (sec): 93.69 - samples/sec: 652.49 - lr: 0.000003
2023-05-11 10:50:38,195 epoch 4 - iter 666/740 - loss 0.00425557 - time (sec): 107.54 - samples/sec: 638.14 - lr: 0.000003
2023-05-11 10:50:51,342 epoch 4 - iter 740/740 - loss 0.00416172 - time (sec): 120.68 - samples/sec: 628.28 - lr: 0.000003
2023-05-11 10:50:51,351 ----------------------------------------------------------------------------------------------------
2023-05-11 10:50:51,352 EPOCH 4 done: loss 0.0042 - lr 0.000003
2023-05-11 10:50:57,146 Evaluating as a multi-label problem: False
2023-05-11 10:50:57,170 DEV : loss 0.006226645316928625 - f1-score (micro avg)  0.875
2023-05-11 10:50:57,177 ----------------------------------------------------------------------------------------------------
2023-05-11 10:51:09,833 epoch 5 - iter 74/740 - loss 0.00540033 - time (sec): 12.65 - samples/sec: 554.76 - lr: 0.000003
2023-05-11 10:51:22,823 epoch 5 - iter 148/740 - loss 0.00491438 - time (sec): 25.64 - samples/sec: 586.89 - lr: 0.000003
2023-05-11 10:51:35,951 epoch 5 - iter 222/740 - loss 0.00361030 - time (sec): 38.76 - samples/sec: 580.01 - lr: 0.000003
2023-05-11 10:51:47,822 epoch 5 - iter 296/740 - loss 0.00292871 - time (sec): 50.64 - samples/sec: 583.90 - lr: 0.000003
2023-05-11 10:51:59,355 epoch 5 - iter 370/740 - loss 0.00319546 - time (sec): 62.17 - samples/sec: 602.46 - lr: 0.000003
2023-05-11 10:52:11,089 epoch 5 - iter 444/740 - loss 0.00295838 - time (sec): 73.90 - samples/sec: 615.43 - lr: 0.000003
2023-05-11 10:52:22,705 epoch 5 - iter 518/740 - loss 0.00295759 - time (sec): 85.52 - samples/sec: 613.55 - lr: 0.000003
2023-05-11 10:52:34,283 epoch 5 - iter 592/740 - loss 0.00279670 - time (sec): 97.10 - samples/sec: 618.58 - lr: 0.000003
2023-05-11 10:52:45,982 epoch 5 - iter 666/740 - loss 0.00271542 - time (sec): 108.80 - samples/sec: 625.80 - lr: 0.000003
2023-05-11 10:52:57,559 epoch 5 - iter 740/740 - loss 0.00304315 - time (sec): 120.37 - samples/sec: 629.90 - lr: 0.000003
2023-05-11 10:52:57,559 ----------------------------------------------------------------------------------------------------
2023-05-11 10:52:57,559 EPOCH 5 done: loss 0.0030 - lr 0.000003
2023-05-11 10:53:02,849 Evaluating as a multi-label problem: False
2023-05-11 10:53:02,862 DEV : loss 0.007544744294136763 - f1-score (micro avg)  0.8696
2023-05-11 10:53:02,876 ----------------------------------------------------------------------------------------------------
2023-05-11 10:53:14,596 epoch 6 - iter 74/740 - loss 0.00240685 - time (sec): 11.72 - samples/sec: 596.71 - lr: 0.000003
2023-05-11 10:53:26,404 epoch 6 - iter 148/740 - loss 0.00133139 - time (sec): 23.53 - samples/sec: 644.31 - lr: 0.000003
2023-05-11 10:53:38,162 epoch 6 - iter 222/740 - loss 0.00159682 - time (sec): 35.28 - samples/sec: 648.35 - lr: 0.000003
2023-05-11 10:53:49,665 epoch 6 - iter 296/740 - loss 0.00135234 - time (sec): 46.79 - samples/sec: 652.75 - lr: 0.000003
2023-05-11 10:54:01,423 epoch 6 - iter 370/740 - loss 0.00117707 - time (sec): 58.55 - samples/sec: 658.12 - lr: 0.000003
2023-05-11 10:54:13,150 epoch 6 - iter 444/740 - loss 0.00137212 - time (sec): 70.27 - samples/sec: 655.96 - lr: 0.000002
2023-05-11 10:54:24,557 epoch 6 - iter 518/740 - loss 0.00238954 - time (sec): 81.68 - samples/sec: 644.04 - lr: 0.000002
2023-05-11 10:54:36,312 epoch 6 - iter 592/740 - loss 0.00258222 - time (sec): 93.44 - samples/sec: 647.83 - lr: 0.000002
2023-05-11 10:54:48,054 epoch 6 - iter 666/740 - loss 0.00228948 - time (sec): 105.18 - samples/sec: 653.51 - lr: 0.000002
2023-05-11 10:54:59,572 epoch 6 - iter 740/740 - loss 0.00222783 - time (sec): 116.69 - samples/sec: 649.75 - lr: 0.000002
2023-05-11 10:54:59,572 ----------------------------------------------------------------------------------------------------
2023-05-11 10:54:59,572 EPOCH 6 done: loss 0.0022 - lr 0.000002
2023-05-11 10:55:05,060 Evaluating as a multi-label problem: False
2023-05-11 10:55:05,076 DEV : loss 0.007937991060316563 - f1-score (micro avg)  0.8936
2023-05-11 10:55:05,091 ----------------------------------------------------------------------------------------------------
2023-05-11 10:55:16,960 epoch 7 - iter 74/740 - loss 0.00539217 - time (sec): 11.87 - samples/sec: 581.78 - lr: 0.000002
2023-05-11 10:55:28,754 epoch 7 - iter 148/740 - loss 0.00360572 - time (sec): 23.66 - samples/sec: 612.10 - lr: 0.000002
2023-05-11 10:55:40,189 epoch 7 - iter 222/740 - loss 0.00290291 - time (sec): 35.10 - samples/sec: 620.82 - lr: 0.000002
2023-05-11 10:55:51,933 epoch 7 - iter 296/740 - loss 0.00259940 - time (sec): 46.84 - samples/sec: 617.91 - lr: 0.000002
2023-05-11 10:56:03,666 epoch 7 - iter 370/740 - loss 0.00213405 - time (sec): 58.57 - samples/sec: 626.74 - lr: 0.000002
2023-05-11 10:56:15,526 epoch 7 - iter 444/740 - loss 0.00176667 - time (sec): 70.43 - samples/sec: 642.24 - lr: 0.000002
2023-05-11 10:56:27,496 epoch 7 - iter 518/740 - loss 0.00226176 - time (sec): 82.40 - samples/sec: 646.47 - lr: 0.000002
2023-05-11 10:56:39,517 epoch 7 - iter 592/740 - loss 0.00197530 - time (sec): 94.43 - samples/sec: 646.65 - lr: 0.000002
2023-05-11 10:56:51,596 epoch 7 - iter 666/740 - loss 0.00176628 - time (sec): 106.50 - samples/sec: 643.68 - lr: 0.000002
2023-05-11 10:57:03,237 epoch 7 - iter 740/740 - loss 0.00159807 - time (sec): 118.15 - samples/sec: 641.78 - lr: 0.000002
2023-05-11 10:57:03,237 ----------------------------------------------------------------------------------------------------
2023-05-11 10:57:03,237 EPOCH 7 done: loss 0.0016 - lr 0.000002
2023-05-11 10:57:08,790 Evaluating as a multi-label problem: False
2023-05-11 10:57:08,802 DEV : loss 0.007489131763577461 - f1-score (micro avg)  0.875
2023-05-11 10:57:08,813 ----------------------------------------------------------------------------------------------------
2023-05-11 10:57:20,728 epoch 8 - iter 74/740 - loss 0.00293591 - time (sec): 11.91 - samples/sec: 660.64 - lr: 0.000002
2023-05-11 10:57:32,330 epoch 8 - iter 148/740 - loss 0.00152475 - time (sec): 23.52 - samples/sec: 647.75 - lr: 0.000002
2023-05-11 10:57:44,042 epoch 8 - iter 222/740 - loss 0.00142454 - time (sec): 35.23 - samples/sec: 663.97 - lr: 0.000002
2023-05-11 10:57:55,844 epoch 8 - iter 296/740 - loss 0.00108701 - time (sec): 47.03 - samples/sec: 653.57 - lr: 0.000001
2023-05-11 10:58:07,400 epoch 8 - iter 370/740 - loss 0.00213925 - time (sec): 58.59 - samples/sec: 653.29 - lr: 0.000001
2023-05-11 10:58:19,085 epoch 8 - iter 444/740 - loss 0.00215007 - time (sec): 70.27 - samples/sec: 642.88 - lr: 0.000001
2023-05-11 10:58:30,728 epoch 8 - iter 518/740 - loss 0.00186291 - time (sec): 81.91 - samples/sec: 642.08 - lr: 0.000001
2023-05-11 10:58:42,497 epoch 8 - iter 592/740 - loss 0.00174759 - time (sec): 93.68 - samples/sec: 643.93 - lr: 0.000001
2023-05-11 10:58:54,134 epoch 8 - iter 666/740 - loss 0.00163518 - time (sec): 105.32 - samples/sec: 650.80 - lr: 0.000001
2023-05-11 10:59:05,712 epoch 8 - iter 740/740 - loss 0.00162918 - time (sec): 116.90 - samples/sec: 648.62 - lr: 0.000001
2023-05-11 10:59:05,712 ----------------------------------------------------------------------------------------------------
2023-05-11 10:59:05,712 EPOCH 8 done: loss 0.0016 - lr 0.000001
2023-05-11 10:59:10,992 Evaluating as a multi-label problem: False
2023-05-11 10:59:11,002 DEV : loss 0.007539280690252781 - f1-score (micro avg)  0.8571
2023-05-11 10:59:11,022 ----------------------------------------------------------------------------------------------------
2023-05-11 10:59:22,914 epoch 9 - iter 74/740 - loss 0.00032775 - time (sec): 11.89 - samples/sec: 614.92 - lr: 0.000001
2023-05-11 10:59:34,713 epoch 9 - iter 148/740 - loss 0.00187759 - time (sec): 23.69 - samples/sec: 633.71 - lr: 0.000001
2023-05-11 10:59:46,353 epoch 9 - iter 222/740 - loss 0.00127548 - time (sec): 35.33 - samples/sec: 627.19 - lr: 0.000001
2023-05-11 10:59:58,002 epoch 9 - iter 296/740 - loss 0.00097988 - time (sec): 46.98 - samples/sec: 651.46 - lr: 0.000001
2023-05-11 11:00:09,713 epoch 9 - iter 370/740 - loss 0.00191914 - time (sec): 58.69 - samples/sec: 653.04 - lr: 0.000001
2023-05-11 11:00:21,491 epoch 9 - iter 444/740 - loss 0.00168477 - time (sec): 70.47 - samples/sec: 647.44 - lr: 0.000001
2023-05-11 11:00:33,337 epoch 9 - iter 518/740 - loss 0.00147968 - time (sec): 82.31 - samples/sec: 648.04 - lr: 0.000001
2023-05-11 11:00:44,827 epoch 9 - iter 592/740 - loss 0.00130334 - time (sec): 93.80 - samples/sec: 649.60 - lr: 0.000001
2023-05-11 11:00:56,362 epoch 9 - iter 666/740 - loss 0.00128199 - time (sec): 105.34 - samples/sec: 646.15 - lr: 0.000001
2023-05-11 11:01:07,973 epoch 9 - iter 740/740 - loss 0.00136433 - time (sec): 116.95 - samples/sec: 648.33 - lr: 0.000001
2023-05-11 11:01:07,973 ----------------------------------------------------------------------------------------------------
2023-05-11 11:01:07,973 EPOCH 9 done: loss 0.0014 - lr 0.000001
2023-05-11 11:01:13,299 Evaluating as a multi-label problem: False
2023-05-11 11:01:13,310 DEV : loss 0.008009959012269974 - f1-score (micro avg)  0.8571
2023-05-11 11:01:13,320 ----------------------------------------------------------------------------------------------------
2023-05-11 11:01:25,144 epoch 10 - iter 74/740 - loss 0.00312104 - time (sec): 11.82 - samples/sec: 651.06 - lr: 0.000001
2023-05-11 11:01:36,678 epoch 10 - iter 148/740 - loss 0.00175109 - time (sec): 23.36 - samples/sec: 599.01 - lr: 0.000000
2023-05-11 11:01:48,228 epoch 10 - iter 222/740 - loss 0.00130076 - time (sec): 34.91 - samples/sec: 616.99 - lr: 0.000000
2023-05-11 11:02:00,078 epoch 10 - iter 296/740 - loss 0.00094637 - time (sec): 46.76 - samples/sec: 636.94 - lr: 0.000000
2023-05-11 11:02:11,859 epoch 10 - iter 370/740 - loss 0.00074838 - time (sec): 58.54 - samples/sec: 646.38 - lr: 0.000000
2023-05-11 11:02:23,280 epoch 10 - iter 444/740 - loss 0.00073967 - time (sec): 69.96 - samples/sec: 654.53 - lr: 0.000000
2023-05-11 11:02:35,041 epoch 10 - iter 518/740 - loss 0.00079782 - time (sec): 81.72 - samples/sec: 652.68 - lr: 0.000000
2023-05-11 11:02:46,697 epoch 10 - iter 592/740 - loss 0.00075560 - time (sec): 93.38 - samples/sec: 655.76 - lr: 0.000000
2023-05-11 11:02:58,443 epoch 10 - iter 666/740 - loss 0.00069141 - time (sec): 105.12 - samples/sec: 652.50 - lr: 0.000000
2023-05-11 11:03:10,013 epoch 10 - iter 740/740 - loss 0.00066460 - time (sec): 116.69 - samples/sec: 649.76 - lr: 0.000000
2023-05-11 11:03:10,013 ----------------------------------------------------------------------------------------------------
2023-05-11 11:03:10,013 EPOCH 10 done: loss 0.0007 - lr 0.000000
2023-05-11 11:03:15,368 Evaluating as a multi-label problem: False
2023-05-11 11:03:15,386 DEV : loss 0.008119435049593449 - f1-score (micro avg)  0.8571
2023-05-11 11:03:15,995 ----------------------------------------------------------------------------------------------------
2023-05-11 11:03:15,995 Testing using last state of model ...
2023-05-11 11:03:23,658 Evaluating as a multi-label problem: False
2023-05-11 11:03:23,668 0.9508	0.9508	0.9508	0.9062
2023-05-11 11:03:23,668 
Results:
- F-score (micro) 0.9508
- F-score (macro) 0.9508
- Accuracy 0.9062

By class:
              precision    recall  f1-score   support

         LOC     0.9508    0.9508    0.9508        61

   micro avg     0.9508    0.9508    0.9508        61
   macro avg     0.9508    0.9508    0.9508        61
weighted avg     0.9508    0.9508    0.9508        61

2023-05-11 11:03:23,668 ----------------------------------------------------------------------------------------------------
